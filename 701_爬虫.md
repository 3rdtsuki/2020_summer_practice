B/S结构

http协议

http请求方法：getpost

#### #xpath解析 etree

```python
import requests
headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36'}
url="https://www.baidu.com/"
res=requests.get(url,headers=headers)
print(res.status_code)


#xpath解析 etree
from lxml import etree
selctor=etree.HTML(res.text)
title_list=selctor.xpath('//*[@id="s-top-left"]/a') #复制xpath，后面加上标签名a
# 新闻的xpath是 '//*[@id="s-top-left"]/a[1]'
# hao123的xpath是'//*[@id="s-top-left"]/a[2]'
# 因此要获取的是a这个数组，下标从1开始
print(title_list)
items=[]
for title in title_list:
    # < a href = "http://news.baidu.com" target = "_blank" class ="mnav c-font-normal c-color-t" > 新闻 < / a >
    title_name=title.xpath('text()')[0] #标题取标签之间text内容
    title_url=title.xpath('@href')[0] #属性href
    item=[title_name,title_url]
    items.append(item)
print(items)
```



从tbody断开，删掉tbody，决定[0]写不写

#### 获取豆瓣电影名&图片：

```python
import csv
import time
path=r"C:\Users\Zhaowei\Desktop\暑假实训\test.csv"
import requests #基于urllib的请求库
import urllib #http请求库
headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36'}
url="https://movie.douban.com/chart"
res=requests.get(url,headers=headers)
print(res.status_code)
#print(res.text)
#xpath解析
from lxml import etree
selctor=etree.HTML(res.text)
title_list=selctor.xpath('//*[@id="content"]/div/div[1]/div/div/table') #复制xpath，后面加上标签名a
items=[]
for title in title_list:
    # < a href = "http://news.baidu.com" target = "_blank" class ="mnav c-font-normal c-color-t" > 新闻 < / a >
    movie_name=title.xpath('tr/td[1]/a/@title')[0]#标题取标签之间text内容//*[@id="content"]/div/div[1]/div/div/table[1]
    movie_name=movie_name.replace(' ','').replace('\n','').replace('/','')
    movie_url=title.xpath('tr/td[1]/a/img/@src')[0] #属性href
    item=[movie_name,movie_url]
    items.append(item)
print(items)
with open(path,'w',encoding="utf-8",newline="")as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['movie name','movie image url'])
    writer.writerows(items)
for i in range(len(items)):
    time.sleep(1)
    img_url=items[i][1]
    r=requests.get(img_url,headers=headers)
    with open(r'C:\Users\Zhaowei\Desktop\暑假实训\电影图片\{}.png'.format(items[i][0]),'wb') as fp:
        fp.write(r.content)
        print(items[i][0])
```

```python
import csv
import time
path=r"C:\Users\Zhaowei\Desktop\暑假实训\test.csv"
import requests #基于urllib的请求库
headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36'}

import random
import json
url='https://movie.douban.com/j/search_subjects?'
# network->
items=[]
for i in range(3):
    params={
        'type':'movie',
        'tag':'热门',
        'sort':'recommend',
        'page_limit':'20',
        'page_start':str(i*20)
    }
    res=requests.get(url,headers=headers,params=params)
    time.sleep(random.randint(1,5))
    data=json.loads(res.text)['subjects']
    for movie in data:
        movie_name=movie['title']
        movie_rate=movie['rate']
        movie_url=movie['url']
        item=[movie_name,movie_rate,movie_url]
        items.append(item)
print(items)
```

beautifulsoup：解析

```python

```

query_string_parameters

urllib.request模块：向服务器发送请求

```python
import urllib.request
import pickle
import socket #超时则报异常
from urllib import request
headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36'}
url='https://search.douban.com/book/subject_search?'
parmas={'search_text':'文艺复兴','cat':'1001'}
parmas=pickle.dumps(parmas)
try:
    req=request.Request(url,headers=headers)
    response=urllib.request.urlopen(req,data=parmas,timeout=3)# 3s则连接超时
    print(response.geturl(),response.getcode())
    print(response.read().decode('utf-8')) # 网页源代码，默认返回二进制，要解码
except socket.timeout:
    print('time out')
```

